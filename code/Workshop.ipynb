{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "we = KeyedVectors.load_word2vec_format('fasttext-sbwc.100k.vec', limit=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.072649 , -0.4433   ,  0.12554  ,  0.049606 , -0.12972  ,\n",
       "        0.32156  , -0.14644  ,  0.20144  , -0.15818  ,  0.12647  ,\n",
       "        0.19597  ,  0.50453  ,  0.01111  ,  0.12758  , -0.11527  ,\n",
       "        0.17277  , -0.10098  , -0.15261  ,  0.062471 , -0.025088 ,\n",
       "       -0.2724   , -0.29719  ,  0.05186  ,  0.044487 ,  0.35225  ,\n",
       "       -0.65213  , -0.0017838,  0.0086409, -0.3108   ,  0.19001  ,\n",
       "        0.26181  , -0.083221 ,  0.074633 , -0.080038 ,  0.34239  ,\n",
       "        0.10485  ,  0.1183   , -0.24124  ,  0.10061  , -0.020331 ,\n",
       "        0.046146 , -0.17905  , -0.49263  ,  0.16665  ,  0.044745 ,\n",
       "        0.22714  ,  0.01891  , -0.42457  ,  0.4272   , -0.050753 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "we['gato'][:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('reina', 0.6306586265563965),\n",
       " ('infanta', 0.5454355478286743),\n",
       " ('princesa', 0.5346059799194336)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "we.most_similar(positive=['rey','mujer'], negative=['hombre'])[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('actriz', 0.7320431470870972),\n",
       " ('cantante', 0.5639584064483643),\n",
       " ('guionista', 0.5555437803268433)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "we.most_similar(positive=['actor','mujer'], negative=['hombre'])[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('feminista', 0.6502466201782227),\n",
       " ('transexual', 0.6304376125335693),\n",
       " ('niña', 0.6294453740119934),\n",
       " ('luchadora', 0.6272600889205933),\n",
       " ('lesbiana', 0.603931188583374),\n",
       " ('trabajadora', 0.595452070236206),\n",
       " ('militante', 0.5916344523429871),\n",
       " ('empresaria', 0.5810160636901855),\n",
       " ('hombre', 0.5789231657981873),\n",
       " ('abogada', 0.5774852633476257)]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "we.most_similar(positive=['mujer','activista'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Puedes probar todas las siguientes relaciones\n",
    "\n",
    "# Algebra\n",
    "\n",
    "# 'dilma' + 'chile' - 'bachelet'\n",
    "# 'dilma' + 'chile' - 'brasil'\n",
    "# 'chile' + 'brasil'\n",
    "# 'microsoft'\n",
    "# 'micorosft' + 'steve'\n",
    "# 'facebook'\n",
    "# 'facebook' + 'bill'\n",
    "\n",
    "# Conjugaciones\n",
    "\n",
    "# 'corría' + 'saltar' - 'correr'\n",
    "# 'corría' + 'ir' - 'correr'\n",
    "\n",
    "# Palabras complejas\n",
    "\n",
    "# 'mujer' + 'yerno' - 'hombre'\n",
    "# 'hombre' + 'nuera' - 'mujer'\n",
    "\n",
    "# no calza\n",
    "\n",
    "# 'abril', 'mayo', 'septiembre', 'martes', 'julio'\n",
    "# 'talca', 'paris', 'londres'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# casos complejos\n",
    "\n",
    "# 'hombre' + 'activista'\n",
    "# 'mujer' + 'activista'\n",
    "# 'hombre' - 'familia'\n",
    "# 'mujer' - 'familia'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploremos datos\n",
    "\n",
    "Dos archivos `dataset_compras.tsv` y `clases.tsv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "colmax 125 mg, 10 comprimidos\t4\r\n",
      "servilletas (paquetes de 50 und c/u)\t3\r\n",
      "caja tapsin comprimidos d/n plus 18 comprimidos\t4\r\n",
      "carne molida cazuela\t0\r\n",
      "toallas de papel favoritas 13 rollos\t3\r\n",
      "guantes de goma aseo\t3\r\n",
      "bolsa cafe molido\t0\r\n",
      "poleras + pantalones mujer\t2\r\n",
      "broca corona (fanta)\t3\r\n",
      "postres manjarate\t0\r\n"
     ]
    }
   ],
   "source": [
    "!head dataset_compras.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alimentos comida bebida carne pollo jugo\r\n",
      "alcohol cigarrillo tabaco\r\n",
      "ropa de vestir calzado zapatos vestidos\r\n",
      "muebles hogar aseo herramienta\r\n",
      "salud medicamento hospital\r\n",
      "transporte bus avion automóvil\r\n",
      "comunicaciones teléfono celular\r\n"
     ]
    }
   ],
   "source": [
    "!head clases.tsv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cargamos los datos de compras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos los datos en una estructura de la forma\n",
    "\n",
    "```\n",
    "compras = [ \n",
    "    (texto_compra_1, int_clase_compra_1),  \n",
    "    (texto_compra_2, int_clase_compra_2),\n",
    "    ...\n",
    "    (texto_compra_N, int_clase_compra_N)\n",
    "]\n",
    "\n",
    "clases = [\n",
    "    texto_clase_1,\n",
    "    texto_clase_2,\n",
    "    ...\n",
    "]```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('pisco alto del carmen 750 ml', 1),\n",
       " ('crema bose tacndimus para tratamiento dermatologico (30grs)', 4),\n",
       " ('poleras de mujer nime', 2),\n",
       " ('examenes mamarios', 4),\n",
       " ('recarga bip', 5),\n",
       " ('viaje taxi trabajo - casa', 5),\n",
       " ('noche', 4),\n",
       " ('resperidona (ansiedad) o dagotil', 4),\n",
       " ('cuello de genero de mujer', 2),\n",
       " ('boletos a villa alemana ida y vuelta', 5)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compras = []\n",
    "with open('dataset_compras.tsv') as f:\n",
    "    for line in f:\n",
    "        glosa, clase = line[:-1].split('\\t')\n",
    "        compras.append((glosa, int(clase)))\n",
    "        \n",
    "# ejemplos\n",
    "compras[100:110]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alimentos comida bebida carne pollo jugo',\n",
       " 'alcohol cigarrillo tabaco',\n",
       " 'ropa de vestir calzado zapatos vestidos',\n",
       " 'muebles hogar aseo herramienta',\n",
       " 'salud medicamento hospital',\n",
       " 'transporte bus avion automóvil',\n",
       " 'comunicaciones teléfono celular']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clases = []\n",
    "with open('clases.tsv') as f:\n",
    "    clases = [line[:-1] for line in f]\n",
    "    \n",
    "clases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectores para frases y  similitud\n",
    "\n",
    "Para convertir una lista de palabras en un vector, simplemente sumamos los vectores, y luego normalizamos el vector resultante:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# si no hemos cargado los embeddings antes lo hacemos ahora\n",
    "# we = KeyedVectors.load_word2vec_format('fasttext-sbwc.100k.vec', limit=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.linalg import norm # para normalizar datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_vector(texto):\n",
    "    tokens = texto.split()\n",
    "    vec = np.zeros(300)\n",
    "    for word in tokens:\n",
    "        # si la palabra está la acumulamos\n",
    "        if word in we:\n",
    "            vec += we[word]\n",
    "    return vec / norm(vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.02160363, -0.13543574, -0.00359645, -0.03332749,  0.07891227,\n",
       "        0.06204042,  0.00753889, -0.04465527,  0.0450577 ,  0.05973038,\n",
       "       -0.08960684, -0.05345259, -0.00115848, -0.04865786,  0.00335951,\n",
       "        0.05654213, -0.02306999,  0.00865327, -0.02585105, -0.05084353,\n",
       "       -0.09082358,  0.01703158,  0.03228194,  0.05585475,  0.00697301,\n",
       "       -0.07326494,  0.07028165, -0.0402126 , -0.04905922, -0.01236731])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texto = 'me gustan los gatos'\n",
    "to_vector(texto)[:30]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hacemos una función para similitud de textos, usando vectores y producto punto de numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def similarity(texto_1, texto_2):\n",
    "    vec_1 = to_vector(texto_1)\n",
    "    vec_2 = to_vector(texto_2)\n",
    "    sim = vec_1 @ vec_2\n",
    "    return sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.720966065387025\n",
      "0.4570526033251019\n",
      "0.6455029211704626\n"
     ]
    }
   ],
   "source": [
    "texto_1 = 'no me gustan los gatos'\n",
    "texto_2 = 'los felinos son lindos'\n",
    "texto_3 = 'quiero comer pizza'\n",
    "\n",
    "print(similarity(texto_1, texto_2))\n",
    "print(similarity(texto_2, texto_3))\n",
    "print(similarity(texto_1, texto_3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clasifica(texto, clases):\n",
    "    sims = [similarity(texto, clase) for clase in clases]\n",
    "    indices = range(len(sims))\n",
    "    ind_max = max(indices, key=lambda i: sims[i])\n",
    "    return ind_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alimentos comida bebida carne pollo jugo\n"
     ]
    }
   ],
   "source": [
    "clase = clasifica(\"un cuarto de lomo liso\", clases)\n",
    "print(clases[clase])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "salud medicamento hospital\n"
     ]
    }
   ],
   "source": [
    "clase = clasifica(\"dos paracetamol para el dolor de cabeza\", clases)\n",
    "print(clases[clase])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "comunicaciones teléfono celular\n"
     ]
    }
   ],
   "source": [
    "clase = clasifica(\"la cuenta del internet\", clases)\n",
    "print(clases[clase])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alcohol cigarrillo tabaco\n"
     ]
    }
   ],
   "source": [
    "clase = clasifica(\"whisky\", clases)\n",
    "print(clases[clase])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clasifica un dato al azar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "glosa compra:\t margarina soprole s\n",
      "clase predicha:\t alimentos comida bebida carne pollo jugo\n",
      "clase real:\t alimentos comida bebida carne pollo jugo\n"
     ]
    }
   ],
   "source": [
    "# elige una compra al azar (índice)\n",
    "i = np.random.randint(len(compras))\n",
    "\n",
    "# clase real\n",
    "(compra, clase_real) = compras[i]\n",
    "clase_pred = clasifica(compra, clases)\n",
    "\n",
    "print('glosa compra:\\t',compra)\n",
    "print('clase predicha:\\t', clases[clase_pred])\n",
    "print('clase real:\\t', clases[clase_real])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tarea: métricas de  acierto\n",
    "\n",
    "Calcula la predicción para todos los texto y compara con la clase real. Usa `classification_report` y `accuracy_score`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.66      0.91      0.76      1176\n",
      "          1       0.79      0.43      0.56       237\n",
      "          2       0.60      0.82      0.69       658\n",
      "          3       0.65      0.46      0.54      1026\n",
      "          4       0.90      0.56      0.69      1016\n",
      "          5       0.73      0.79      0.76       737\n",
      "          6       0.70      0.88      0.78       150\n",
      "\n",
      "avg / total       0.72      0.69      0.68      5000\n",
      "\n",
      "Accuracy: 0.6936\n",
      "CPU times: user 1.75 s, sys: 164 ms, total: 1.92 s\n",
      "Wall time: 2.14 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Hacemos la predicción para los primeros 5000 ejemplos\n",
    "\n",
    "pred = []\n",
    "real = []\n",
    "\n",
    "for compra, clase_real in compras[:5000]:\n",
    "    clase_pred = clasifica(compra, clases)\n",
    "    pred.append(clase_pred)\n",
    "    real.append(clase_real)\n",
    "\n",
    "print(classification_report(real, pred))\n",
    "print(\"Accuracy:\", accuracy_score(real, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorización\n",
    "\n",
    "El anterios código tarda demasiado para clasificar todos los ejemplos. Para mejorar radicalmente el tiempo de ejecución podemos convertir todo en operación de matrices. Primero creamos una matriz con todos los vectores representantes de cada texto de compra, y luego una con los vectores de las clases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape =  (572080, 300)\n",
      "C.shape =  (7, 300)\n",
      "CPU times: user 19.3 s, sys: 6.21 s, total: 25.5 s\n",
      "Wall time: 29 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# pon todos los vectores de compras en una matriz\n",
    "compras_vectores = [to_vector(texto) for texto, cls in compras]\n",
    "X = np.vstack(compras_vectores)\n",
    "\n",
    "# pon todos los vectores de clases en una matriz\n",
    "clases_vectores = [to_vector(cls) for cls in clases]\n",
    "C = np.vstack(clases_vectores)\n",
    "\n",
    "print('X.shape =',X.shape)\n",
    "print('C.shape =',C.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora podemos calcular la similitud con una simple multiplicación de matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.67      0.92      0.78    140032\n",
      "          1       0.77      0.43      0.55     25936\n",
      "          2       0.59      0.82      0.69     74864\n",
      "          3       0.66      0.45      0.53    116992\n",
      "          4       0.89      0.56      0.69    116720\n",
      "          5       0.72      0.80      0.76     82732\n",
      "          6       0.68      0.89      0.77     14804\n",
      "\n",
      "avg / total       0.72      0.69      0.68    572080\n",
      "\n",
      "Accuracy: 0.6949657390574745\n",
      "CPU times: user 1.46 s, sys: 1.03 s, total: 2.49 s\n",
      "Wall time: 1.77 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "#calcula las similitudes como un producto punto\n",
    "similitudes = X @ C.T\n",
    "\n",
    "pred = np.argmax(similitudes, axis=1)\n",
    "real = [cls for _, cls in compras]\n",
    "\n",
    "print(classification_report(real, pred))\n",
    "print(\"Accuracy:\", accuracy_score(real, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
