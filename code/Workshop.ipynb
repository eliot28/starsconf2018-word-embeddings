{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "we = KeyedVectors.load_word2vec_format('fasttext-sbwc.100k.vec', limit=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "we['gato'][:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "we.most_similar(positive=['rey','mujer'], negative=['hombre'])[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "we.most_similar(positive=['actor','mujer'], negative=['hombre'])[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "we.most_similar(positive=['mujer','activista'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Los anteriores ejemplos muestran esta relación\n",
    "\n",
    "# 'rey' + 'mujer' - 'hombre'\n",
    "# 'actor' + 'mujer' - 'hombre'\n",
    "\n",
    "# Puedes probar tu las siguientes relaciones\n",
    "\n",
    "# 'dilma' + 'chile' - 'bachelet'\n",
    "# 'dilma' + 'chile' - 'brasil'\n",
    "# 'chile' + 'brasil'\n",
    "# 'microsoft'\n",
    "# 'micorosft' + 'steve'\n",
    "# 'facebook'\n",
    "# 'facebook' + 'bill'\n",
    "\n",
    "# Conjugaciones\n",
    "\n",
    "# 'corría' + 'saltar' - 'correr'\n",
    "# 'corría' + 'ir' - 'correr'\n",
    "\n",
    "# Palabras complejas\n",
    "\n",
    "# 'mujer' + 'yerno' - 'hombre'\n",
    "# 'hombre' + 'nuera' - 'mujer'\n",
    "\n",
    "# no calza\n",
    "\n",
    "# 'abril', 'mayo', 'septiembre', 'martes', 'julio'\n",
    "# 'talca', 'paris', 'londres'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# casos complejos\n",
    "\n",
    "# 'hombre' + 'activista'\n",
    "# 'mujer' + 'activista'\n",
    "# 'hombre' - 'familia'\n",
    "# 'mujer' - 'familia'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploremos datos\n",
    "\n",
    "Dos archivos `dataset_compras.tsv` y `clases.tsv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!head dataset_compras.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!head clases.tsv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cargamos los datos de compras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos los datos en una estructura de la forma\n",
    "\n",
    "```\n",
    "compras = [ \n",
    "    (texto_compra_1, int_clase_compra_1),  \n",
    "    (texto_compra_2, int_clase_compra_2),\n",
    "    ...\n",
    "    (texto_compra_N, int_clase_compra_N)\n",
    "]\n",
    "\n",
    "clases = [\n",
    "    texto_clase_1,\n",
    "    texto_clase_2,\n",
    "    ...\n",
    "]```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compras = []\n",
    "with open('dataset_compras.tsv') as f:\n",
    "    for line in f:\n",
    "        glosa, clase = line[:-1].split('\\t')\n",
    "        compras.append((glosa, int(clase)))\n",
    "        \n",
    "# ejemplos\n",
    "compras[100:110]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clases = []\n",
    "with open('clases.tsv') as f:\n",
    "    clases = [line[:-1] for line in f]\n",
    "    \n",
    "clases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectores para frases y  similitud\n",
    "\n",
    "Para convertir una lista de palabras en un vector, simplemente sumamos los vectores, y luego normalizamos el vector resultante:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# si no hemos cargado los embeddings antes lo hacemos ahora\n",
    "# we = KeyedVectors.load_word2vec_format('fasttext-sbwc.100k.vec', limit=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.linalg import norm # para normalizar datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_vector(texto):\n",
    "    tokens = texto.split()\n",
    "    vec = np.zeros(300)\n",
    "    for word in tokens:\n",
    "        # si la palabra está la acumulamos\n",
    "        if word in we:\n",
    "            vec += we[word]\n",
    "    return vec / norm(vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texto = 'me gustan los gatos'\n",
    "to_vector(texto)[:30]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hacemos una función para similitud de textos, usando vectores y producto punto de numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def similarity(texto_1, texto_2):\n",
    "    vec_1 = to_vector(texto_1)\n",
    "    vec_2 = to_vector(texto_2)\n",
    "    sim = vec_1 @ vec_2\n",
    "    return sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texto_1 = 'no me gustan los gatos'\n",
    "texto_2 = 'los felinos son lindos'\n",
    "texto_3 = 'quiero comer pizza'\n",
    "\n",
    "print(similarity(texto_1, texto_2))\n",
    "print(similarity(texto_2, texto_3))\n",
    "print(similarity(texto_1, texto_3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clasifica(texto, clases):\n",
    "    sims = [similarity(texto, clase) for clase in clases]\n",
    "    indices = range(len(sims))\n",
    "    ind_max = max(indices, key=lambda i: sims[i])\n",
    "    return ind_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clase = clasifica(\"un cuarto de lomo liso\", clases)\n",
    "print(clases[clase])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clase = clasifica(\"dos paracetamol para el dolor de cabeza\", clases)\n",
    "print(clases[clase])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clase = clasifica(\"la cuenta del internet\", clases)\n",
    "print(clases[clase])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clase = clasifica(\"whisky\", clases)\n",
    "print(clases[clase])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clasifica un dato al azar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# elige una compra al azar (índice)\n",
    "i = np.random.randint(len(compras))\n",
    "\n",
    "# clase real\n",
    "(compra, clase_real) = compras[i]\n",
    "clase_pred = clasifica(compra, clases)\n",
    "\n",
    "print('glosa compra:\\t',compra)\n",
    "print('clase predicha:\\t', clases[clase_pred])\n",
    "print('clase real:\\t', clases[clase_real])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tarea: métricas de  acierto\n",
    "\n",
    "Calcula la predicción para todos los texto y compara con la clase real. Usa `classification_report` y `accuracy_score`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Hacemos la predicción para los primeros 5000 ejemplos\n",
    "\n",
    "pred = []\n",
    "real = []\n",
    "\n",
    "for compra, clase_real in compras[:5000]:\n",
    "    clase_pred = clasifica(compra, clases)\n",
    "    pred.append(clase_pred)\n",
    "    real.append(clase_real)\n",
    "\n",
    "print(classification_report(real, pred))\n",
    "print(\"Accuracy:\", accuracy_score(real, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorización\n",
    "\n",
    "El anterios código tarda demasiado para clasificar todos los ejemplos. Para mejorar radicalmente el tiempo de ejecución podemos convertir todo en operación de matrices. Primero creamos una matriz con todos los vectores representantes de cada texto de compra, y luego una con los vectores de las clases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# pon todos los vectores de compras en una matriz\n",
    "compras_vectores = [to_vector(texto) for texto, cls in compras]\n",
    "X = np.vstack(compras_vectores)\n",
    "\n",
    "# pon todos los vectores de clases en una matriz\n",
    "clases_vectores = [to_vector(cls) for cls in clases]\n",
    "C = np.vstack(clases_vectores)\n",
    "\n",
    "print('X.shape =',X.shape)\n",
    "print('C.shape =',C.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora podemos calcular la similitud con una simple multiplicación de matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "#calcula las similitudes como un producto punto\n",
    "similitudes = X @ C.T\n",
    "\n",
    "pred = np.argmax(similitudes, axis=1)\n",
    "real = [cls for _, cls in compras]\n",
    "\n",
    "print(classification_report(real, pred))\n",
    "print(\"Accuracy:\", accuracy_score(real, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
